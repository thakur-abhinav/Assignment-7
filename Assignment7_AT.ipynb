{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment7.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "72o_liGtHqt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PKEwLdHJjx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e360038b-62bc-48d3-f377-73ee183977aa"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/'\n",
        "'''\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "file = 'shakespeare_input.txt'\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import files\\nuploaded = files.upload()\\nfile = 'shakespeare_input.txt'\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyTUBXlVKd-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#opening file and reading data and making char2id,id2char dictionaries\n",
        "filepath='/content/gdrive/My Drive/Colab Notebooks/shakespeare_input.txt'\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8')\n",
        "dictionary = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(dictionary)}\n",
        "idx2char = np.array(dictionary)\n",
        "text= np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UJHjE5-LbAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(c):\n",
        "    '''\n",
        "    This function splits a given sequence into input and\n",
        "    output characters.\n",
        "    '''\n",
        "    input_text = c[:-1]\n",
        "    target_text = c[1:]\n",
        "    return input_text, target_text\n",
        "  \n",
        "seq_length=100\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "dataset = dataset.shuffle(10000).batch(64, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ixbh-SZLt9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "70924d60-f818-4dcf-c686-bdd8ca38ce1e"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  '''\n",
        "  This function builds a lstm model, with first layers as\n",
        "  embedding. Second as lstm and then a dense layer with\n",
        "  dictionary size output.\n",
        "  '''\n",
        "  model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "  tf.keras.layers.LSTM(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'),\n",
        "  tf.keras.layers.Dense(vocab_size)])\n",
        "  return model\n",
        "\n",
        "model = build_model(vocab_size = len(dictionary),embedding_dim=256,rnn_units=512,batch_size=64)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (64, None, 512)           1574912   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (64, None, 67)            34371     \n",
            "=================================================================\n",
            "Total params: 1,626,435\n",
            "Trainable params: 1,626,435\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i0Zd_LyMMpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  \n",
        "  '''\n",
        "  This function returns the cross entropy loss.\n",
        "  '''\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False, clipnorm = 5)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "checkpoint_dir = '/content/gdrive/My Drive/Colab Notebooks/Checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEznFDnrNWSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "950b9747-a6db-4a61-ed00-485fcc3aa1e0"
      },
      "source": [
        "#fitting the model and plotting loss curve\n",
        "history = model.fit(dataset, epochs=15, steps_per_epoch=64, callbacks=[checkpoint_callback])\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0703 11:12:36.211042 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer\n",
            "W0703 11:12:36.212492 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0703 11:12:36.213868 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0703 11:12:36.218329 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0703 11:12:36.220155 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0703 11:12:36.222227 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0703 11:12:36.223495 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "W0703 11:12:36.224541 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "W0703 11:12:36.226265 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "W0703 11:12:36.228098 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "W0703 11:12:36.229887 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "W0703 11:12:36.231103 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "W0703 11:12:36.232275 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "W0703 11:12:36.233434 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "W0703 11:12:36.235800 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "W0703 11:12:36.237401 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "W0703 11:12:36.238982 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "W0703 11:12:36.240664 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "W0703 11:12:36.242637 140704702592896 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "W0703 11:12:36.245757 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer\n",
            "W0703 11:12:36.247751 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0703 11:12:36.250046 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0703 11:12:36.252066 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0703 11:12:36.254729 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0703 11:12:36.256809 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0703 11:12:36.258518 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "W0703 11:12:36.260345 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "W0703 11:12:36.262203 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "W0703 11:12:36.264554 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "W0703 11:12:36.266515 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "W0703 11:12:36.268428 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "W0703 11:12:36.270227 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "W0703 11:12:36.272008 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "W0703 11:12:36.274104 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "W0703 11:12:36.276084 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "W0703 11:12:36.278168 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "W0703 11:12:36.279690 140704702592896 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "W0703 11:12:36.281471 140704702592896 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 40s 624ms/step - loss: 3.2337\n",
            "Epoch 2/15\n",
            "64/64 [==============================] - 36s 563ms/step - loss: 2.4439\n",
            "Epoch 3/15\n",
            "64/64 [==============================] - 36s 559ms/step - loss: 2.2075\n",
            "Epoch 4/15\n",
            "64/64 [==============================] - 35s 554ms/step - loss: 2.0783\n",
            "Epoch 5/15\n",
            "64/64 [==============================] - 35s 552ms/step - loss: 1.9769\n",
            "Epoch 6/15\n",
            "64/64 [==============================] - 35s 547ms/step - loss: 1.9123\n",
            "Epoch 7/15\n",
            "64/64 [==============================] - 35s 553ms/step - loss: 1.8469\n",
            "Epoch 8/15\n",
            "64/64 [==============================] - 35s 551ms/step - loss: 1.7937\n",
            "Epoch 9/15\n",
            "64/64 [==============================] - 35s 546ms/step - loss: 1.7485\n",
            "Epoch 10/15\n",
            "64/64 [==============================] - 35s 542ms/step - loss: 1.7001\n",
            "Epoch 11/15\n",
            "64/64 [==============================] - 35s 548ms/step - loss: 1.6666\n",
            "Epoch 12/15\n",
            " 3/64 [>.............................] - ETA: 32s - loss: 1.6706"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0703 11:19:07.526247 140704702592896 training_generator.py:235] Your dataset ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 960 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/64 [>.............................] - ETA: 35s - loss: 1.6706"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff7bfe7ec18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X181fV99/HXJzcQckMSkgMCSQhg\nUkDlRgOiIgjYaW+m3WrbtZs66y5q51Zdu2vt3GPd3Hb1Wmfrus521qrVqnNd1V21trW1guBNBRJu\n5f4egkASQkIId7n5XH+cQ4hpIAc84ZfzO+/n45FHTs75nnM+R+GdH9/f9/f9mLsjIiLhkhZ0ASIi\nkngKdxGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCSOEuIhJCGUG9cXFxsZeXlwf1\n9iIiSammpqbB3SN9jQss3MvLy6murg7q7UVEkpKZ7YpnnKZlRERCSOEuIhJCCncRkRBSuIuIhJDC\nXUQkhBTuIiIhpHAXEQmhpAv3zQda+KeX1nO8rSPoUkREBqykC/faQ0d59I0dLN/ZGHQpIiIDVp/h\nbmZZZrbMzFab2Tozu7+XMV80s/VmtsbMXjWzMf1TLswcV8Sg9DSWbK7vr7cQEUl68Ry5nwDmufsU\nYCpwo5nN7DFmJVDl7pOB54B/SWyZp2UPyqCqvJAlmxv66y1ERJJen+HuUUdiP2bGvrzHmEXufjT2\n49tASUKr7GFOZYRNB1rY33y8P99GRCRpxTXnbmbpZrYKqANecfelZxl+J/CLM7zOAjOrNrPq+vrz\nn1aZXRndEG3JFk3NiIj0Jq5wd/cOd59K9Ih8hpld2ts4M/sjoAp44Ayv84i7V7l7VSTS546VZzTh\nojyG5w3WvLuIyBmc02oZd28CFgE39nzMzK4H/ga4yd1PJKa83pkZ11ZEeGNrAx2d3vcTRERSTDyr\nZSJmVhC7PQT4ILCxx5hpwPeIBntdfxTa0+zKYpqOtrGmtulCvJ2ISFKJ58h9JLDIzNYAy4nOub9k\nZv9gZjfFxjwA5AI/NrNVZvZiP9Xb5dqKCGZo1YyISC/67MTk7muAab3c/9Vut69PcF19GpYziMtG\n57NkSz33XF9xod9eRGRAS7orVLubXRFh1Z4mmo+1BV2KiMiAktzhXhmho9N5a6umZkREukvqcJ9W\nVkDu4AytdxcR6SGpwz0zPY1rLi5iyeYG3LUkUkTklKQOd4hOzextOsa2+tagSxERGTCSP9wrYlsR\n6GpVEZEuSR/upcOyGVeco3l3EZFukj7cITo18/b2g+rOJCISE5JwL+Z4W6e6M4mIxIQi3NWdSUTk\nvUIR7urOJCLyXqEId4jOu6s7k4hIVHjCvULdmURETglNuE8cmUdE3ZlERIAQhbuZMVvdmUREgBCF\nO5zuzrR2b3PQpYiIBCqeNntZZrbMzFab2Tozu7+XMYPN7EdmttXMlppZeX8U25fT3Zk0NSMiqS2e\nI/cTwDx3nwJMBW40s5k9xtwJHHL3i4F/Bb6e2DLj09WdSeEuIimuz3D3qCOxHzNjXz0ntW8Gnozd\nfg6Yb2aWsCrPweyKCCvVnUlEUlxcc+5mlm5mq4A6og2yl/YYMhrYA+Du7UAzUJTIQuOl7kwiInGG\nu7t3uPtUoASYYWaXns+bmdkCM6s2s+r6+v6ZOlF3JhGRc1wt4+5NwCLgxh4P7QVKAcwsA8gHDvby\n/EfcvcrdqyKRyPlV3IfM9DSuHq/uTCKS2uJZLRMxs4LY7SHAB4GNPYa9CNweu30LsNADTFZ1ZxKR\nVBfPkftIYJGZrQGWE51zf8nM/sHMboqNeQwoMrOtwBeBr/RPufGZU6nuTCKS2jL6GuDua4Bpvdz/\n1W63jwOfSGxp5690WDZjY92ZPjtrbNDliIhccKG6QrW7OerOJCIpLLThfqo7U/XOQ0GXIiJywYU2\n3Lu6M2lJpIikoNCG+6nuTIs3KdxFJPWENtxB3ZlEJHWFO9zVnUlEUlSow13dmUQkVYU63M2MayuK\n1Z1JRFJOqMMdouvd1Z1JRFJN6MN91sXF6s4kIikn9OFelDuYS0epO5OIpJbQhztEp2ZW7mni8HF1\nZxKR1JAS4a7uTCKSalIi3E91Z1qsqRkRSREpEe7qziQiqSYlwh3UnUlEUks8bfZKzWyRma03s3Vm\ndk8vY/LN7Kdmtjo25o7+Kff8qTuTiKSSeI7c24EvufskYCZwt5lN6jHmbmC9u08BrgO+aWaDElrp\n+9S9O5OISNj1Ge7uvs/dV8RutwAbgNE9hwF5ZmZALtBI9JfCgDK7oljdmUQkJZzTnLuZlRPtp7q0\nx0MPAROBd4G1wD3u3pmA+hJqdmVE3ZlEJCXEHe5mlgs8D9zr7od7PHwDsAoYBUwFHjKzob28xgIz\nqzaz6vr6Cz89MnNcEZnppqkZEQm9uMLdzDKJBvsz7v5CL0PuAF7wqK3ADmBCz0Hu/oi7V7l7VSQS\neT91n5ecwRlMLx+mk6oiEnrxrJYx4DFgg7s/eIZhu4H5sfEjgA8A2xNVZCLNroywcX8LBw6rO5OI\nhFc8R+7XALcC88xsVezrw2Z2l5ndFRvzj8DVZrYWeBX4srsPyGv9u7oz6ehdREIso68B7v4GYH2M\neRf4nUQV1Z9OdWdavLmeT1SVBl2OiEi/SJkrVE9RdyYRSQUpF+6g7kwiEn4pGe7qziQiYZeS4a7u\nTCISdikZ7gCzK4vVnUlEQit1w71C3ZlEJLxSNtwvH1MY686kcBeR8EnZcD/dnale3ZlEJHRSNtzh\ndHem7Q3qziQi4ZLS4X6qO9PiTVo1IyLhktLhru5MIhJWKR3uoO5MIhJOCnd1ZxKREEr5cFd3JhEJ\no5QP95zBGVSNUXcmEQmXlA93UHcmEQkfhTvRfWZAu0SKSHjE00O11MwWmdl6M1tnZvecYdx1sRZ8\n68xsceJL7T8TLxpKce5glmzRVgQiEg59ttkD2oEvufsKM8sDaszsFXdff2qAmRUA3wVudPfdZja8\nn+rtF2lpxuzKYhZtrKOj00lPO2tXQRGRAa/PI3d33+fuK2K3W4ANwOgewz4DvODuu2Pj6hJdaH+b\nUxnhkLoziUhInNOcu5mVA9OApT0eqgQKzew1M6sxs9vO8PwFZlZtZtX19QNrflvdmUQkTOIOdzPL\nBZ4H7nX3wz0ezgCuAD4C3AD8rZlV9nwNd3/E3avcvSoSibyPshNP3ZlEJEziCnczyyQa7M+4+wu9\nDKkFfunure7eACwBpiSuzAtD3ZlEJCziWS1jwGPABnd/8AzDfgLMMrMMM8sGriQ6N59U1J1JRMIi\nntUy1wC3AmvNbFXsvvuAMgB3f9jdN5jZy8AaoBN41N3f6Y+C+1P37kw3Xjoy6HJERM5bn+Hu7m8A\nfa4NdPcHgAcSUVRQMtPTuKpbd6boP1pERJKPrlDtQd2ZRCQMFO49zKmIruLRqhkRSWYK9x7KirIp\nL8pWuItIUlO492JOZYTfqDuTiCQxhXsv1J1JRJKdwr0X6s4kIslO4d4LdWcSkWSncD8DdWcSkWSm\ncD8DdWcSkWSmcD8DdWcSkWSmcD+DtDRjdkUxb2ypp6PTgy5HROScKNzPYnasO9M76s4kIklG4X4W\nsyo07y4iyUnhfhbFuYO5bHQ+P1u7T1erikhSUbj34a4549m4v4UvPLuS9o7OoMsREYmLwr0PH5k8\nkr//3Un8av0BvvLCWjp1clVEkkA8bfZKzWyRma03s3Vmds9Zxk43s3YzuyWxZQbrj68Zy73XV/Bc\nTS1f+/kG3BXwIjKwxdNmrx34kruvMLM8oMbMXnH39d0HmVk68HXgV/1QZ+DumV9B09E2Hn1jB4U5\ng7h77sVBlyQickbxtNnbB+yL3W4xsw3AaGB9j6F/DjwPTE90kQOBmfHVj06i+VgbD/xyE0OHZHLr\nzDFBlyUi0qt4jty7mFk5MA1Y2uP+0cDvAXM5S7ib2QJgAUBZWdm5VToApKUZ/3LLZFqOt/HVn7xD\n/pBMbpoyKuiyRER+S9wnVM0sl+iR+b3ufrjHw98CvuzuZ11O4u6PuHuVu1dFIpFzr3YAyExP46HP\nXM708mF88UerWLSpLuiSRER+S1zhbmaZRIP9GXd/oZchVcB/mdlO4Bbgu2b2sYRVOcBkZabz6O1V\nfOCiPD7/dA3VOxuDLklE5D3iWS1jwGPABnd/sLcx7j7W3cvdvRx4DvhTd/9/Ca10gBmalcmTn53B\nqPwh3PHEcta/2/MfMyIiwYnnyP0a4FZgnpmtin192MzuMrO7+rm+Aa04dzBP/cmV5A7O4LbHl7Gz\noTXokkREALCg1mxXVVV5dXV1IO+daFvrjvDJ7/2G7EHpPHfX1VyUnxV0SSISUmZW4+5VfY3TFaoJ\ncPHwXJ64YzqHWk9y62NLOdR6MuiSRCTFKdwTZHJJAd+/vYpdjUe544nltJ5oD7okEUlhCvcEunp8\nMQ99ehpr9zbzuadqONGunSRFJBgK9wT7nUsu4usfn8wbWxu4979WqYuTiARC4d4PbrmihL/96CR+\n8c5+7nthrTYaE5EL7py2H5D43TlrLE1HT/LvC7dSkJPJX39oYtAliUgKUbj3oy9+sJKmo218b/F2\nCoYM4vPXjQ+6JBFJEQr3fmRm3H/TJTQfa+PrL2+kIDuTT89Ivg3TRCT5KNz7WVqa8c1PTqHleBv3\n/c9ahmZl8pHJI4MuS0RCTidUL4DM9DS++4dXUDWmkHt/tJIlm+uDLklEQk7hfoEMGZTOo7dP5+Lh\neXzuqRpqdh0KuiQRCTGF+wWUPySTH352BiOGDuazTyxn437tJCki/UPhfoFF8gbz1J1XkpWZxq2P\nLWP3waNBlyQiIaRwD0DpsGyevvNK2jo6+aPHllJ3+HjQJYlIyCjcA1IxIo8n7phBw5ET3PrYMpqP\ntgVdkoiEiMI9QFNLC3jk1ip2NLRyxxPLOHpSO0mKSGLE02av1MwWmdl6M1tnZvf0MuYPzWyNma01\ns7fMbEr/lBs+syqK+fanp7JqTxOfe6qGk+1n7TEuIhKXeI7c24EvufskYCZwt5lN6jFmBzDH3S8D\n/hF4JLFlhtuNl47kn39/Mq9vaeAv/ls7SYrI+9fnFaruvg/YF7vdYmYbgNHA+m5j3ur2lLeBkgTX\nGXqfnF5K07GTfO3nG2k8cpL7b76EyhF5QZclIknqnObczawcmAYsPcuwO4FfnH9JqWvB7PF87fcu\nY/2+w3zo317nH366nuZjOtEqIucu7gbZZpYLLAb+j7u/cIYxc4HvArPc/WAvjy8AFgCUlZVdsWvX\nrvOtO9QaW0/yjV9t4tlluynKGcRf3TCBW64oIS3Ngi5NRAIWb4PsuMLdzDKBl4BfuvuDZxgzGfgf\n4EPuvrmv16yqqvLq6uo+3zuVvbO3mb97cR01uw4xpSSf+2++lKmlBUGXJSIBijfc41ktY8BjwIaz\nBHsZ8AJwazzBLvG5dHQ+z911Ff/6qSnsaz7Ox77zJv/7x6upbzkRdGkiMsD1eeRuZrOA14G1wKl1\nevcBZQDu/rCZPQp8HDg1z9Le128WHbmfmyMn2vn3V7fw+Js7yMpI594PVnLbVWPITNelCiKpJKHT\nMv1B4X5+ttUf4f6frmfJ5noqhufy9zddwjUXFwddlohcIAmblpGBZXwklyfvmM73b6viRHsnf/jo\nUj7/dA21h7QBmYicpk5MScjM+OCkEVxbUcyjr2/noUVbWbixjs9fN5675ownKzM96BJFJGA6ck9i\nWZnp/Nm8ChZ+6TqunzSCb/16C9c/uJiX39lPUNNtIjIwKNxDYFTBEL7zmct59n/NJGdQBnc9XcNt\njy9ja11L0KWJSEAU7iFy1fgifvaFWfz9705i9Z4mbvzW6/zTS+tpOa6rXEVSjcI9ZDLS0/jja8ay\n6C+v4xNVJTz25g7mfmMxz9XU0qkNyURShsI9pIpyB/N/f38yP7n7GkqHDeEvf7yajz/8Fmtqm4Iu\nTUQuAIV7yE0uKeD5u67mm5+Ywp7GY9z8nTf5yvNrOHhEV7mKhJnCPQWkpRkfv6KERX85hz+ZNZbn\namq57huv8YM3d9DeoeYgImGkcE8heVmZ/M1HJvHyvdcytbSA+3+6ng9/+3VeXP2uQl4kZBTuKeji\n4Xn88LMzeOTWK2jvdL7w7ErmfvM1fvibnRw72RF0eSKSANpbJsV1djq/3nCAhxdvY8XuJoblDOL2\nq8q57aoxFOYMCro8EelBG4fJOVu+s5HvLd7GrzfUMSQznU9NL+VPrh1LSWF20KWJSEy84a69ZaTL\n9PJhTC8fxuYDLTyyZDvPLN3FU2/v4ncnj2TB7PFMGjU06BJFJE46cpcz2td8jMff2MF/Lt1N68kO\nZldGuGvOOK4aV0S0h4uIXGialpGEaT7WxtNv7+IHb+6k4cgJppTk87k547nhkotIV19XkQsqkW32\nSs1skZmtN7N1ZnZPL2PMzL5tZlvNbI2ZXX6+hcvAkz8kk7vnXswbX57L137vMg4fb+dPn1nBvG++\nxtNv7+J4m1bYiAw08bTZGwmMdPcVZpYH1AAfc/f13cZ8GPhz4MPAlcC/ufuVZ3tdHbknr45O55X1\n+/mPxdtZvaeJ4txB/PHV5dw6s5z87MygyxMJtYSdUHX3fcC+2O0WM9sAjAbWdxt2M/BDj/6meNvM\nCsxsZOy5EjLpacaNl47khksuYumORh5evI1v/Goz331tG5+eUcads8YyqmBI0GWKpLRzWi1jZuXA\nNGBpj4dGA3u6/Vwbu0/hHmJmxsxxRcwcV8SGfYf5/pLtPPnWTp58ayc3TR3F52aP5wMX5QVdpkhK\nivsKVTPLBZ4H7nX3w+fzZma2wMyqzay6vr7+fF5CBqiJI4fy4Kemsviv5nLbVeW8/M5+bvjWEj77\nxHKWbj+ozlAiF1hcq2XMLBN4Cfiluz/Yy+PfA15z92djP28CrjvbtIzm3MOt6ehJnvrNLp54aycH\nW08ytbSAu+aM53cmjSBNK2xEzlvClkJadEHzk0Cju997hjEfAf6M0ydUv+3uM872ugr31HC8rYMf\n19Ty/SXb2d14lFH5WcybOJz5E0Zw1fgiNfMWOUeJDPdZwOvAWuDU1oH3AWUA7v5w7BfAQ8CNwFHg\nDnc/a3Ir3FNLR6fz8jv7+cmqvbyxtYGjJzvIykzj6vHFzJswnHkThuskrEgcdBGTDFgn2jtYur2R\nhRvrWLixjt2NRwGYcFEecycMZ/6E4UwrK9QFUiK9ULhLUnB3ttW3snDjARZurKN65yHaO52C7Ezm\nVEaYN2E4cyojFGRrh0oRULhLkmo+1sbrW+pZuLGO1zbV09h6kjSDK8YUMm/CCOZNGE7liFztbSMp\nS+EuSa+j01ld28Si2PTNunejK3BHFwzpmqfXSVlJNQp3CZ39zcdZtKmOVzfU8ebWBo61RU/KXjO+\nmLk6KSspQuEuoXa8rYOlOxpZuOEACzfVsafxGBA9KXvqqF4nZSWMFO6SMqInZY/w6obo9E31rkN0\nxE7KXlcZYf7EEcyujJA/RJuaSfJTuEvKaj7WxpLNp07K1nHoaBsZacb08mHMnxg9qh8XyQ26TJHz\nonAXIXpSduXuQ7y6sY6FG+rYdKAFgHHFOdHpm4nDmV4+jMz0uLdZEgmUwl2kF3saj7JwYx2vbqzj\n7W0HOdnRSV5WBnMqI1w/cQRzKiMU5mhNvQxcCneRPrSeaOf1LQ2xC6jqaThyomtN/fyJI5g/YTgX\nD9eaehlYFO4i56Cz01mzt5mFGw7warc19WXDspk3YTjzJw7nyrFFDMrQ9I0ES+Eu8j7saz4W3ftm\nQx1vbG3gRHsnuYMzuLYiutHZ3AnDKc4dHHSZkoIU7iIJcuxkB29ta+g6Kbv/8HHMYGppAddPjG6J\nMOGiPE3fyAWhcBfpB+7OuncPd52UXb2nCYhuiTB3QoSrxhUzfWwhw/OyAq5UwkrhLnIB1LUc57WN\n9by68QBvbGmg9WQHEF1qOWPssK6vksLsgCuVsFC4i1xg7R2drHv3MMt2NLJ0RyPLdzbSfKwNiB7Z\ndw/7ccU5msaR85LITkyPAx8F6tz90l4ezweeJtqZKQP4hrv/oK83VrhL2HV2OpsOtLBsR2NX4Dcc\nOQFAce5gruwW9h8YkafeshKXRIb7bOAI8MMzhPt9QL67f9nMIsAm4CJ3P3m211W4S6pxd3Y0tL4n\n7Pc2RTc8G5qV0e3IvohLRg3VVbPSq3jDPaOvAe6+xMzKzzYEyIv1Uc0FGoH2OOsUSRlmxrhILuMi\nufzBjDIAag8d7Qr7ZTsa+fWGOgCyB6VzxZhCZpRHA39KaYH2rZdz0me4x+Eh4EXgXSAP+JS7d579\nKSICUFKYTUlhNr9/eQkQPUG7fMchlu04yNIdjXzzlc0ADMpIY2ppQddUzuVlheQMTsRfXwmruE6o\nxo7cXzrDtMwtwDXAF4HxwCvAFHc/3MvYBcACgLKysit27dr1fmoXCb2moydZvjMa9st2NPLOu4fp\n6HTS04xJI4cyuSSfKSUFXFaST8XwXDI0lRN6CV0t00e4/wz4Z3d/PfbzQuAr7r7sbK+pOXeRc3fk\nRDsrdh1i6Y6DrNzdxNraZlpORGdBh2Smc8mooUwuKWByST6TS/IpL8rRidqQSdicexx2A/OB181s\nBPABYHsCXldEesgdnMHsygizKyNAdEXOjoOtrKltYk1tM2tqm/nPZbt4/M3ozGheVgaTS/K5bHQB\nU0rymVxawKj8LC3DTAHxrJZ5FrgOKAYOAH8HZAK4+8NmNgp4AhgJGNGj+Kf7emMduYv0j/aOTrbU\nHWFNbROra5tZU9vExn0ttHdG/64X5w7istH53Y7wC4jkaZ+cZKGLmESky/G2Djbub+l2hN/Elroj\nnPrrPyo/i8mxuftTc/hqSzgwXchpGREZ4LIy05laWsDU0oKu+1pPtPPO3mbW7m3uOsJ/ed3+rsfL\ni7K7ju6nlBZw6ah8hgzScsxkoXAXSVE5gzO4clwRV44r6rqv6ehJ1u6Nzt2v3tPE8p2NvLj6XQDS\n04yJI/O4vKyQaWUFTCstZExRtubvByhNy4jIWdUdPs6a2mZW7jnEyt1NrN7T1LVB2rCcQUwrLeDy\nMYVMKy1gcmkBuVp/3680LSMiCTF8aBbXT8ri+kkjgGjT8c0HWli5u4kVuw91NSAHSDOoHJHXFfbT\nygoZV6zlmEHQkbuIvG9NR0+yak9TV+Cv2tNEy/Ho+vv8IZlMLS3oms6ZWlbA0CydrD1fWi0jIoHp\n7HS21R9h5e4mVu45xIpdTWyua8EdzODiSO7pufuyQiqG5+roPk4KdxEZUFqOt7F6TzMrdx+KTufs\naaLpaHS/+7zBGUwpLeDyWNhPLS2gMGdQwBUPTJpzF5EBJS8rk1kVxcyqKAaiWyDvPHiUFbsOdR3d\nP7RoK7FrrSjOHcS44lzGRXKiX7HbZcOytYdOHBTuIhIIM2NscQ5ji3P4+BXRXTFbT7THlmI2sa2u\nle0NR3hl/QEOtp5uD5GRZowpyo5tn5zD+K5fALkM09F+F4W7iAwYOYMzmDmuiJnd1t4DNB9tY1vD\nEbbXt7K9Pvp9W/0RFm+q52TH6R3GC7IzGVec0xX844pzGR/JYUxRDoMyUutoX+EuIgNefnYml5cV\ncnlZ4Xvu7+h0ag8d7Qr77Q3R8F+yuZ7namq7xqWnGaWFQ6Kh3z38IzlEcgfHdSFWZ6fT1tlJe4fT\n3um0d3RGv8dut3U4HZ1OW0cnHZ1Oe+d77+t6Xmcn44pzmTRqaML/O3WncBeRpJWeZowpih6Zz50w\n/D2PtRxvY0dDLPTrW7t+Aby5tYET7aeP9vMGZxDJG/xbgd0V0h3RUE/k2pPPzRmncBcROR95WZmx\nvXEK3nN/Z6fzbvOx01M8Da0cbD1JZpqRnpZGZrqRkW5kpKWRkWZkpJ/6bmSmp5GeZmSknb6deWps\nt++Z6bHXij2/57gLcW5A4S4iKSUtzbraG57aFz+MUusMg4hIilC4i4iEkMJdRCSE+gx3M3vczOrM\n7J2zjLnOzFaZ2TozW5zYEkVE5FzFc+T+BHDjmR40swLgu8BN7n4J8InElCYiIuerz3B39yVA41mG\nfAZ4wd13x8bXJag2ERE5T4mYc68ECs3sNTOrMbPbzjTQzBaYWbWZVdfX1yfgrUVEpDeJCPcM4Arg\nI8ANwN+aWWVvA939EXevcveqSCS860tFRIKWiIuYaoGD7t4KtJrZEmAKsPlsT6qpqWkws13n+Z7F\nQMN5PjcZhPnz6bMlrzB/vmT6bGPiGZSIcP8J8JCZZQCDgCuBf+3rSe5+3ofuZlYdz2b1ySrMn0+f\nLXmF+fOF8bP1Ge5m9ixwHVBsZrXA3wGZAO7+sLtvMLOXgTVAJ/Cou59x2aSIiPS/PsPd3T8dx5gH\ngAcSUpGIiLxvyXqF6iNBF9DPwvz59NmSV5g/X+g+W2ANskVEpP8k65G7iIicRdKFu5ndaGabzGyr\nmX0l6HoSxcxKzWyRma2P7dFzT9A1JZqZpZvZSjN7KehaEs3MCszsOTPbaGYbzOyqoGtKFDP7i9if\nyXfM7Fkzywq6pvejt/2yzGyYmb1iZlti3wvP9hrJIKnC3czSge8AHwImAZ82s0nBVpUw7cCX3H0S\nMBO4O0Sf7ZR7gA1BF9FP/g142d0nEL3OIxSf08xGA18Aqtz9UiAd+INgq3rfnuC398v6CvCqu1cA\nr8Z+TmpJFe7ADGCru29395PAfwE3B1xTQrj7PndfEbvdQjQcRgdbVeKYWQnRq5gfDbqWRDOzfGA2\n8BiAu59096Zgq0qoDGBI7FqWbODdgOt5X86wX9bNwJOx208CH7ugRfWDZAv30cCebj/XEqIAPMXM\nyoFpwNJgK0mobwF/RfRaiLAZC9QDP4hNOz1qZjlBF5UI7r4X+AawG9gHNLv7r4Ktql+McPd9sdv7\ngRFBFpMIyRbuoWdmucDzwL3ufjjoehLBzD4K1Ll7TdC19JMM4HLgP9x9GtBKCP5ZDxCbe76Z6C+w\nUUCOmf1RsFX1L48uIUz6ZYTJFu57gdJuP5fE7gsFM8skGuzPuPsLQdeTQNcAN5nZTqJTafPM7Olg\nS0qoWqDW3U/9S+s5omEfBtdHwyDJAAABCUlEQVQDO9y93t3bgBeAqwOuqT8cMLORALHvSb91ebKF\n+3KgwszGmtkgoid2Xgy4poQwMyM6Z7vB3R8Mup5Ecve/dvcSdy8n+v9sobuH5ujP3fcDe8zsA7G7\n5gPrAywpkXYDM80sO/ZndD4hOVncw4vA7bHbtxPdMyupJWLjsAvG3dvN7M+AXxI9a/+4u68LuKxE\nuQa4FVhrZqti993n7j8PsCaJ358Dz8QOOrYDdwRcT0K4+1Izew5YQXRF10qS/GrOM+yX9c/Af5vZ\nncAu4JPBVZgYukJVRCSEkm1aRkRE4qBwFxEJIYW7iEgIKdxFREJI4S4iEkIKdxGREFK4i4iEkMJd\nRCSE/j/yeh+PKonmIwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd7X3diJNxj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "9ef58ca0-a7d3-4ce8-8ec1-2529f661b72c"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  '''\n",
        "  This function generates a sequence of characters by taking\n",
        "  a seed as the start string.\n",
        "  '''\n",
        "  num_generate = 1000\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  temperature = 1.0\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n",
        "\n",
        "tf.train.latest_checkpoint(checkpoint_dir)\n",
        "model = build_model(vocab_size = len(dictionary),embedding_dim=256,rnn_units=512,batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "print(generate_text(model, start_string=u\"Gods poured thy thunder on the face of Earth. \")) "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gods poured thy thunder on the face of Earth. I priece you,\n",
            "Hat we come fellionous eyes godness adlibence.\n",
            "\n",
            "BECDORW:\n",
            "Let me:\n",
            "Whonesomatt sutcho's a rine ecour all thee leave lang the\n",
            "that t owd not thuse as Porcessaid,\n",
            "With you hee, priff in this every what me,\n",
            "World these trige thy dods Marnct five and at forse;\n",
            "And ca hid Musing king.\n",
            "\n",
            "SIMON:\n",
            "Thou have servants me, Sirain?''ther some, that's nworth\n",
            "deshembity a gidle rapurech's was confeik and in too was.\n",
            "\n",
            "IANGO:\n",
            "Thouselt's my wital.\n",
            "\n",
            "Plown:\n",
            "By devemnatant, then cout, and thinm, be\n",
            "the Cure of than seef thy deat\n",
            "Thou are one what it what if the best?\n",
            "\n",
            "BASTHARCS:\n",
            "Luty you knywere!\n",
            "He linghow that your majagat to hever a fancest ploce\n",
            "That a fear of him and given togthes:\n",
            "A bread toogh: 'Wight thou\n",
            "Eaqurious of Surid his miracion\n",
            "Neces these they by your lipey of Vasish,\n",
            "Look you, this weel up, our, whyselfous a\n",
            "bears, co you arvent; I'll secus\n",
            "As good me? evey of Mackleas! Ake them's gentle this ince:\n",
            "I'll no hencefored me one of all as dore,\n",
            "Samet the purs and thoughts and him e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38gNlDwatKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}